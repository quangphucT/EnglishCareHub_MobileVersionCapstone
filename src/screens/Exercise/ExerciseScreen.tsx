import React, { useState, useEffect, useRef, useCallback } from "react";
import {
  View,
  Text,
  ScrollView,
  TouchableOpacity,
  ActivityIndicator,
  Alert,
  Platform,
} from "react-native";
import { SafeAreaView } from "react-native-safe-area-context";
import { Ionicons } from "@expo/vector-icons";
import { useNavigation, useRoute } from "@react-navigation/native";
import { Audio } from "expo-av";
import { Video, ResizeMode } from "expo-av";
import { File, Paths } from "expo-file-system";
import { useLearnerStore } from "../../store/learnerStore";
import { useLearningPathCourseFull } from "../../hooks/learner/learningPath/learningPathHooks";
import {
  useStartExercise,
  useSubmitAnswerQuestion,
} from "../../hooks/learner/exercise/exerciseHooks";

interface RouteParams {
  exerciseId: string;
  chapterId?: string;
  refetchLearningPath?: () => void;
}

// Component ƒë·ªÉ hi·ªÉn th·ªã text c√≥ m√†u xanh/ƒë·ªè d·ª±a tr√™n k·∫øt qu·∫£ ph√°t √¢m
interface ColoredTextProps {
  text: string;
  letterCorrectMask: string; // VD: "111 1110 10" - m·ªói t·ª´ c√°ch nhau b·ªüi space, 1 = ƒë√∫ng, 0 = sai
}

const ColoredText: React.FC<ColoredTextProps> = ({ text, letterCorrectMask }) => {
  if (!text || !letterCorrectMask) {
    return <Text className="text-2xl font-semibold text-gray-900">{text}</Text>;
  }

  const words = text.split(" ");
  const masks = letterCorrectMask.split(" ");

  return (
    <View className="flex-row flex-wrap justify-center">
      {words.map((word, wordIdx) => {
        const mask = masks[wordIdx] || "";
        return (
          <View key={wordIdx} className="flex-row mr-2 mb-1">
            {word.split("").map((letter, letterIdx) => {
              const isCorrect = mask[letterIdx] === "1";
              return (
                <Text
                  key={letterIdx}
                  className="text-2xl font-semibold"
                  style={{ color: isCorrect ? "#10B981" : "#EF4444" }}
                >
                  {letter}
                </Text>
              );
            })}
          </View>
        );
      })}
    </View>
  );
};

const ExerciseScreen = () => {
  const navigation = useNavigation();
  const route = useRoute();
  const { exerciseId, chapterId, refetchLearningPath } =
    route.params as RouteParams;

  const currentCourse = useLearnerStore((state) => state.currentCourse);

  // Get full learning path data
  const {
    data: apiResponse,
    isLoading,
    refetch,
  } = useLearningPathCourseFull(
    {
      learningPathCourseId: currentCourse?.learningPathCourseId || "",
      courseId: currentCourse?.courseId || "",
    },
    Boolean(currentCourse)
  );
  // Refetch data when screen mounts (for "Xem l·∫°i" or "Ti·∫øp t·ª•c h·ªçc")
  useEffect(() => {
    refetch();
    if (refetchLearningPath) {
      refetchLearningPath();
    }
  }, [exerciseId]);

  const { mutate: startExercise } = useStartExercise();
  const { mutate: submitAnswerQuestion } = useSubmitAnswerQuestion();

  const [currentQuestionIndex, setCurrentQuestionIndex] = useState(0);
  const [isRecording, setIsRecording] = useState(false);
  const [recorded, setRecorded] = useState<boolean[]>([]);
  const [isProcessingAudio, setIsProcessingAudio] = useState(false);
  const [isPlayingAudio, setIsPlayingAudio] = useState(false);
  const [isSpeaking, setIsSpeaking] = useState(false);
  const [pronunciationScores, setPronunciationScores] = useState<number[]>([]);
  // State ƒë·ªÉ theo d√µi c√¢u n√†o ƒë√£ ghi √¢m trong session hi·ªán t·∫°i (ch·ªâ hi·ªán k·∫øt qu·∫£ khi ghi √¢m m·ªõi)
  const [recordedInSession, setRecordedInSession] = useState<boolean[]>([]);
  const [ipaTranscripts, setIpaTranscripts] = useState<string[]>([]);
  const [realIpaTranscripts, setRealIpaTranscripts] = useState<string[]>([]);
  const [coloredContents, setColoredContents] = useState<string[]>([]);
  // State ƒë·ªÉ l∆∞u d·ªØ li·ªáu ph√¢n t√≠ch t·ª´ng k√Ω t·ª± (ƒë·ªÉ render m√†u xanh/ƒë·ªè)
  const [letterCorrectData, setLetterCorrectData] = useState<string[]>([]);
  const [AIExplainTheWrongForVoiceAI, setAIExplainTheWrongForVoiceAI] =
    useState<string[]>([]);
  const [learnerAnswerIds, setLearnerAnswerIds] = useState<string[]>([]);

  const recordingRef = useRef<Audio.Recording | null>(null);
  const soundRef = useRef<Audio.Sound | null>(null);
  const recordedAudioUriRef = useRef<string | null>(null);

  // AI API config
  const apiMainPathSTS = process.env.EXPO_PUBLIC_AI_STS_API_URL;
  const STScoreAPIKey = process.env.EXPO_PUBLIC_AI_STS_API_KEY || "";
  const AILanguage = process.env.EXPO_PUBLIC_AI_STS_LANGUAGE || "en";

  // Find current exercise from learning path data
  const currentExerciseData = React.useMemo(() => {
    if (!apiResponse?.data?.chapters || !exerciseId) return null;

    for (const chapter of apiResponse.data.chapters) {
      const exercise = chapter.exercises.find(
        (ex) => ex.exerciseId === exerciseId
      );
      if (exercise) return exercise;
    }
    return null;
  }, [apiResponse, exerciseId]);

  const questions = React.useMemo(() => {
    if (!currentExerciseData?.questions) return [];
    return currentExerciseData.questions.sort(
      (a, b) => a.orderIndex - b.orderIndex
    );
  }, [currentExerciseData]);

  const currentQuestion = questions[currentQuestionIndex];
  const totalQuestions = questions.length;
  const progressPercentage =
    ((currentQuestionIndex + 1) / totalQuestions) * 100;

  // Initialize recorded state based on question status
  useEffect(() => {
    if (questions.length > 0 && recorded.length === 0) {
      // Mark questions as recorded if they are already completed
      const initialRecorded = questions.map(
        (q) => q.status?.toLowerCase() === "completed"
      );
      setRecorded(initialRecorded);

      // Initialize scores from existing question scores
      const initialScores = questions.map((q) => q.score || 0);
      setPronunciationScores(initialScores);

      setIpaTranscripts(new Array(questions.length).fill(""));
      setRealIpaTranscripts(new Array(questions.length).fill(""));
      setColoredContents(new Array(questions.length).fill(""));
      setLetterCorrectData(new Array(questions.length).fill(""));
      setAIExplainTheWrongForVoiceAI(new Array(questions.length).fill(""));
      setLearnerAnswerIds(new Array(questions.length).fill(""));
      // M·∫∑c ƒë·ªãnh kh√¥ng c√≥ c√¢u n√†o ƒë∆∞·ª£c ghi √¢m trong session n√†y
      setRecordedInSession(new Array(questions.length).fill(false));
    }
  }, [questions, recorded.length]);

  // Ki·ªÉm tra exercise ƒëang ·ªü tr·∫°ng th√°i n√†o (NotStarted = b·∫Øt ƒë·∫ßu h·ªçc, kh√°c = ti·∫øp t·ª•c h·ªçc)
  const isNewExercise = currentExerciseData?.status === "NotStarted";

  const convertBlobToBase64 = useCallback(
    async (blob: Blob): Promise<string> => {
      return new Promise((resolve, reject) => {
        const reader = new FileReader();
        reader.readAsDataURL(blob);
        reader.onload = () => resolve(reader.result as string);
        reader.onerror = (error) => reject(error);
      });
    },
    []
  );

  // Request audio permissions
  useEffect(() => {
    (async () => {
      const { status } = await Audio.requestPermissionsAsync();
      if (status !== "granted") {
        Alert.alert("L·ªói", "C·∫ßn c·∫•p quy·ªÅn ghi √¢m ƒë·ªÉ s·ª≠ d·ª•ng ch·ª©c nƒÉng n√†y");
      }
      await Audio.setAudioModeAsync({
        allowsRecordingIOS: true,
        playsInSilentModeIOS: true,
      });
    })();
  }, []);

  // Start exercise when screen loads (only if NotStarted)
  useEffect(() => {
    if (
      currentExerciseData?.learningPathExerciseId &&
      currentExerciseData.status === "NotStarted"
    ) {
    
      startExercise({
        learningPathExerciseId: currentExerciseData.learningPathExerciseId,
        status: "InProgress",
      });
    } else {
      console.log("üìù Exercise status:", currentExerciseData?.status);
    }
  }, [currentExerciseData]);

  const handleRecord = async () => {
    if (isRecording) {
      // Stop recording
      try {
        setIsRecording(false);
        setIsProcessingAudio(true);

        if (!recordingRef.current) return;

        await recordingRef.current.stopAndUnloadAsync();
        const uri = recordingRef.current.getURI();

        if (!uri) {
          setIsProcessingAudio(false);
          return;
        }

        // Convert to blob and base64 for AI processing
        const response = await fetch(uri);
        const blob = await response.blob();
        const base64 = await convertBlobToBase64(blob);

        if (!base64 || base64.length < 6) {
          setIsProcessingAudio(false);
          return;
        }

        try {
          const text = currentQuestion?.text || "";
          const payload = {
            title: text,
            base64Audio: base64,
            language: AILanguage,
          };

          const res = await fetch(
            apiMainPathSTS + "/GetAccuracyFromRecordedAudio",
            {
              method: "POST",
              body: JSON.stringify(payload),
              headers: {
                "Content-Type": "application/json",
                "X-Api-Key": STScoreAPIKey,
              },
            }
          );

          if (!res.ok) {
            throw new Error(`API Error: ${res.status} ${res.statusText}`);
          }

          const data = await res.json();

          const acc = parseFloat(data.pronunciation_accuracy);

          // Store results
          const newScores = [...pronunciationScores];
          newScores[currentQuestionIndex] = acc;
          setPronunciationScores(newScores);

          const newIpa = [...ipaTranscripts];
          newIpa[currentQuestionIndex] = `/ ${data.ipa_transcript} /`;
          setIpaTranscripts(newIpa);

          const newRealIpa = [...realIpaTranscripts];
          newRealIpa[currentQuestionIndex] = data.real_transcripts_ipa
            ? `/ ${data.real_transcripts_ipa} /`
            : "";
          setRealIpaTranscripts(newRealIpa);

          // Color code words
          const isLetterCorrectAll: string[] = String(
            data.is_letter_correct_all_words || ""
          ).split(" ");
          const words = text.split(" ");
          let coloredWords = "";

          for (let wordIdx = 0; wordIdx < words.length; wordIdx++) {
            const word = words[wordIdx];
            const lettersMask = isLetterCorrectAll[wordIdx] || "";
            let wordTemp = "";

            for (let letterIdx = 0; letterIdx < word.length; letterIdx++) {
              const ok = lettersMask[letterIdx] === "1";
              const color = ok ? "#10B981" : "#EF4444";
              wordTemp += `<span style="color: ${color}">${word[letterIdx]}</span>`;
            }
            coloredWords += ` ${wordTemp}`;
          }

          const newColored = [...coloredContents];
          newColored[currentQuestionIndex] = coloredWords.trim();
          setColoredContents(newColored);

          // L∆∞u d·ªØ li·ªáu is_letter_correct_all_words ƒë·ªÉ render m√†u
          const newLetterData = [...letterCorrectData];
          newLetterData[currentQuestionIndex] = data.is_letter_correct_all_words || "";
          setLetterCorrectData(newLetterData);

          const newRecorded = [...recorded];
          newRecorded[currentQuestionIndex] = true;
          setRecorded(newRecorded);

          // ƒê√°nh d·∫•u ƒë√£ ghi √¢m trong session hi·ªán t·∫°i
          const newRecordedInSession = [...recordedInSession];
          newRecordedInSession[currentQuestionIndex] = true;
          setRecordedInSession(newRecordedInSession);

          // Store AI explanation
          const newAIExplain = [...AIExplainTheWrongForVoiceAI];
          newAIExplain[currentQuestionIndex] = data.explain_the_wrong || "";
          setAIExplainTheWrongForVoiceAI(newAIExplain);

          // Submit answer to server
          submitAnswerQuestion(
            {
              learningPathQuestionId: currentQuestion.learningPathQuestionId,
              audioRecordingUrl: uri,
              transcribedText: data.ipa_transcript || "",
              scoreForVoice: acc,
              explainTheWrongForVoiceAI: data.explain_the_wrong || "",
            },
            {
              onSuccess: (response) => {
                const newAnswerIds = [...learnerAnswerIds];
                newAnswerIds[currentQuestionIndex] =
                  response.data.learnerAnswerId;
                setLearnerAnswerIds(newAnswerIds);
                setIsProcessingAudio(false);

              },
              onError: (error) => {
                setIsProcessingAudio(false);
                Alert.alert("L·ªói", "Kh√¥ng th·ªÉ l∆∞u c√¢u tr·∫£ l·ªùi");
              },
            }
          );
        } catch (error) {
          console.error("Error processing audio:", error);
          setIsProcessingAudio(false);
          Alert.alert("L·ªói", "Kh√¥ng th·ªÉ ph√¢n t√≠ch √¢m thanh");
        }
      } catch (error) {
        console.error("Failed to stop recording:", error);
        setIsProcessingAudio(false);
        Alert.alert("L·ªói", "Kh√¥ng th·ªÉ d·ª´ng ghi √¢m");
      }
    } else {
      // Start recording
      try {
        await Audio.setAudioModeAsync({
          allowsRecordingIOS: true,
          playsInSilentModeIOS: true,
        });

        const { recording: newRecording } = await Audio.Recording.createAsync(
          Audio.RecordingOptionsPresets.HIGH_QUALITY
        );

        recordingRef.current = newRecording;
        setIsRecording(true);
      } catch (error) {
        console.error("Failed to start recording:", error);
        Alert.alert("L·ªói", "Kh√¥ng th·ªÉ b·∫Øt ƒë·∫ßu ghi √¢m");
      }
    }
  };

  const handlePlayRecording = async () => {
    try {
      if (!recordingRef.current) return;

      const uri = recordingRef.current.getURI();
      if (!uri) return;

      setIsPlayingAudio(true);

      const { sound } = await Audio.Sound.createAsync({ uri });
      soundRef.current = sound;

      await sound.playAsync();

      sound.setOnPlaybackStatusUpdate((status) => {
        if (status.isLoaded && status.didJustFinish) {
          setIsPlayingAudio(false);
          sound.unloadAsync();
        }
      });
    } catch (error) {
      console.error("Failed to play recording:", error);
      setIsPlayingAudio(false);
      Alert.alert("L·ªói", "Kh√¥ng th·ªÉ ph√°t l·∫°i b·∫£n ghi");
    }
  };

  // Text-to-Speech cho c√¢u h·ªèi - g·ªçi API backend ƒë·ªÉ l·∫•y audio
  const handleSpeakQuestion = useCallback(async () => {
    if (!currentQuestion?.text) return;

    try {
      setIsSpeaking(true);

      // Stop any ongoing audio
      if (soundRef.current) {
        await soundRef.current.stopAsync();
        await soundRef.current.unloadAsync();
        soundRef.current = null;
      }

      // G·ªçi API backend ƒë·ªÉ l·∫•y audio TTS
      const response = await fetch(`${apiMainPathSTS}/getAudioFromText`, {
        method: 'POST',
        body: JSON.stringify({
          value: currentQuestion.text.trim(),
        }),
        headers: {
          'Content-Type': 'application/json',
          'X-Api-Key': STScoreAPIKey,
        },
      });

      const responseData = await response.json();
      console.log('TTS API response received');

      // Parse response
      let data;
      if (responseData.body) {
        if (typeof responseData.body === 'string') {
          data = JSON.parse(responseData.body);
        } else {
          data = responseData.body;
        }
      } else if (responseData.wavBase64) {
        data = responseData;
      } else {
        data = responseData;
      }

      if (data && data.wavBase64) {
        // T·∫°o file trong cache directory
        const audioFile = new File(Paths.cache, `tts_audio_${Date.now()}.mp3`);

        // Decode base64 v√† ghi v√†o file
        const binaryString = atob(data.wavBase64);
        const bytes = new Uint8Array(binaryString.length);
        for (let i = 0; i < binaryString.length; i++) {
          bytes[i] = binaryString.charCodeAt(i);
        }
        audioFile.write(bytes);

        console.log('Audio saved to:', audioFile.uri);

        // Ph√°t audio t·ª´ file
        const { sound } = await Audio.Sound.createAsync(
          { uri: audioFile.uri },
          { shouldPlay: true }
        );
        soundRef.current = sound;

        // L·∫Øng nghe khi audio k·∫øt th√∫c
        sound.setOnPlaybackStatusUpdate((status) => {
          if (status.isLoaded && status.didJustFinish) {
            setIsSpeaking(false);
            sound.unloadAsync();
            soundRef.current = null;
            // X√≥a file t·∫°m
            try { audioFile.delete(); } catch (e) { }
          }
        });
      } else {
        console.error('No wavBase64 field in TTS response:', data);
        setIsSpeaking(false);
        Alert.alert('L·ªói', 'Kh√¥ng th·ªÉ l·∫•y audio t·ª´ server');
      }
    } catch (error) {
      console.error('Error playing TTS audio:', error);
      setIsSpeaking(false);
      Alert.alert('L·ªói', 'Kh√¥ng th·ªÉ ph√°t audio');
    }
  }, [currentQuestion, apiMainPathSTS, STScoreAPIKey]);

  const handleNextQuestion = () => {
    if (currentQuestionIndex < totalQuestions - 1) {
      setCurrentQuestionIndex(currentQuestionIndex + 1);
    }
  };

  const handlePreviousQuestion = () => {
    if (currentQuestionIndex > 0) {
      setCurrentQuestionIndex(currentQuestionIndex - 1);
    }
  };

  // const handleSubmit = () => {
  //   Alert.alert("Ho√†n th√†nh b√†i t·∫≠p", "B·∫°n ƒë√£ ho√†n th√†nh b√†i t·∫≠p!", [
  //     {
  //       text: "OK",
  //       onPress: () => (navigation as any).goBack(),
  //     },
  //   ]);
  // };

  if (isLoading) {
    return (
      <View className="flex-1 justify-center items-center bg-white">
        <ActivityIndicator size="large" color="#3B82F6" />
        <Text className="mt-4 text-gray-600">ƒêang t·∫£i b√†i t·∫≠p...</Text>
      </View>
    );
  }

  if (!currentQuestion) {
    return (
      <View className="flex-1 justify-center items-center bg-white">
        <Text className="text-gray-600">Kh√¥ng t√¨m th·∫•y c√¢u h·ªèi</Text>
      </View>
    );



  }

  return (
    <SafeAreaView
      className="flex-1 bg-gradient-to-br from-gray-50 to-blue-50"
      edges={["top", "bottom"]}
    >
      {/* Header */}
      <View className="bg-white border-b border-gray-200 shadow-sm">
        <View className="px-6 py-4">
          <View className="flex-row items-center justify-between">
            <View className="flex-row items-center gap-3">
              <TouchableOpacity onPress={() => navigation.goBack()}>
                <Ionicons name="arrow-back" size={24} color="#374151" />
              </TouchableOpacity>
              <View>
                <Text className="text-lg font-bold text-gray-900">
                  {currentExerciseData?.exerciseTitle || "Exercise"}
                </Text>
                <Text className="text-xs text-gray-500" numberOfLines={2}>
                  {currentExerciseData?.exerciseDescription || ""}
                </Text>
              </View>
            </View>

          </View>
        </View>
      </View>

      {/* Progress bar */}
      <View className="bg-white border-b border-gray-100">
        <View className="px-6 py-3">
          <View className="h-2 bg-gray-200 rounded-full overflow-hidden">
            <View
              className="h-full bg-gradient-to-r from-blue-500 to-purple-500 rounded-full"
              style={{ width: `${progressPercentage}%` }}
            />
          </View>
          {/* Mini progress indicators */}
          <View className="flex-row justify-between mt-2">
            {questions.map((_, index) => (
              <View
                key={index}
                className={`h-1 flex-1 mx-0.5 rounded-full ${index < currentQuestionIndex
                    ? "bg-green-500"
                    : index === currentQuestionIndex
                      ? "bg-blue-500"
                      : "bg-gray-200"
                  }`}
              />
            ))}
          </View>
        </View>
      </View>

      <ScrollView className="flex-1 px-6" contentContainerStyle={{ paddingBottom: 20 }}>
        {/* Question type badge */}
        {/* <View className="items-center my-6">
          <View className="px-6 py-2 bg-gradient-to-r from-purple-600 to-blue-600 rounded-full">
            <Text className="text-white text-sm font-semibold uppercase">
              {currentQuestion.type === "word"
                ? "T·ª´ v·ª±ng"
                : currentQuestion.type === "sentence"
                ? "C√¢u"
                : "ƒêo·∫°n vƒÉn"}
            </Text>
          </View>
        </View> */}

        {/* Video kh·∫©u h√¨nh (n·∫øu c√≥) */}
        {currentQuestion?.media && currentQuestion.media.length > 0 && (
          <View className="mb-6">
            {currentQuestion.media.map((mediaItem: any, idx: number) => (
              <View key={mediaItem.questionMediaId || idx}>
                {mediaItem.videoUrl && (
                  <View className="bg-blue-50 border-2 border-blue-200 rounded-2xl p-4 mb-4">
                    <View className="flex-row items-center gap-2 mb-3">
                      <View className="w-8 h-8 bg-blue-500 rounded-full items-center justify-center">
                        <Ionicons name="videocam" size={16} color="white" />
                      </View>
                      <View>
                        <Text className="text-sm font-semibold text-blue-900">
                          Video h∆∞·ªõng d·∫´n kh·∫©u h√¨nh
                        </Text>
                        <Text className="text-xs text-blue-700">
                          Quan s√°t v√† b·∫Øt ch∆∞·ªõc c√°ch ƒë·∫∑t mi·ªáng khi ph√°t √¢m
                        </Text>
                      </View>
                    </View>
                    <Video
                      source={{ uri: mediaItem.videoUrl }}
                      style={{ width: "100%", height: 300, borderRadius: 12 }}
                      useNativeControls
                      resizeMode={ResizeMode.CONTAIN}
                      isLooping
                    />
                  </View>
                )}
              </View>
            ))}
          </View>
        )}
        {/* Processing status */}
        {isProcessingAudio && (
          <View className="mb-4 bg-blue-50 border-l-4 border-blue-500 rounded-lg p-4">
            <View className="flex-row items-center gap-3">
              <ActivityIndicator size="small" color="#2563EB" />
              <View>
                <Text className="text-blue-900 font-semibold">
                  ƒêang ph√¢n t√≠ch √¢m thanh...
                </Text>
                <Text className="text-blue-700 text-xs">
                  AI ƒëang ƒë√°nh gi√° ph√°t √¢m c·ªßa b·∫°n
                </Text>
              </View>
            </View>
          </View>
        )}
        {/* Question text */}
        <View className="items-center mb-6">
          {/* Text c√¢u h·ªèi */}
          <Text className="text-3xl font-bold text-gray-900 text-center leading-relaxed px-2">
            {currentQuestion.text}
          </Text>

          {/* N√∫t nghe ph√°t √¢m - t√°ch ri√™ng d∆∞·ªõi text */}
          <TouchableOpacity 
            onPress={handleSpeakQuestion} 
            disabled={isSpeaking}
            className="mt-4 flex-row items-center bg-indigo-100 px-4 py-2 rounded-full"
            style={{ opacity: isSpeaking ? 0.6 : 1 }}
          >
            <Ionicons
              name={isSpeaking ? "volume-high" : "volume-high-outline"}
              size={22}
              color="#4f46e5"
            />
            <Text className="text-indigo-700 font-semibold ml-2 text-sm">
              {isSpeaking ? "ƒêang ph√°t..." : "Nghe ph√°t √¢m"}
            </Text>
          </TouchableOpacity>
        </View>

        {/* Question stats - Ch·ªâ hi·ªán khi ti·∫øp t·ª•c h·ªçc (kh√¥ng ph·∫£i b·∫Øt ƒë·∫ßu h·ªçc m·ªõi) */}
        {!isNewExercise && (currentQuestion.score > 0 || currentQuestion.numberOfRetake > 0) && (
          <View className="flex-row justify-center gap-4 mb-6">
            {currentQuestion.score >= 0 && (
              <View className="bg-blue-50 border border-blue-200 rounded-lg px-4 py-2">
                <View className="flex-row items-center gap-2">
                  <Ionicons name="star" size={16} color="#2563EB" />
                  <View>
                    <Text className="text-xs text-blue-700 font-medium">
                      ƒêi·ªÉm g·∫ßn nh·∫•t
                    </Text>
                    <Text className="text-lg font-bold text-blue-900">
                      {currentQuestion.score}/100
                    </Text>
                  </View>
                </View>
              </View>
            )}
            {currentQuestion.numberOfRetake > 0 && (
              <View className="bg-orange-50 border border-orange-200 rounded-lg px-4 py-2">
                <View className="flex-row items-center gap-2">
                  <Ionicons name="refresh" size={16} color="#EA580C" />
                  <View>
                    <Text className="text-xs text-orange-700 font-medium">
                      S·ªë l·∫ßn l√†m l·∫°i
                    </Text>
                    <Text className="text-lg font-bold text-orange-900">
                      {currentQuestion.numberOfRetake}
                    </Text>
                  </View>
                </View>
              </View>
            )}
          </View>
        )}

        {/* Recording result - Ch·ªâ hi·ªán khi ghi √¢m m·ªõi trong session hi·ªán t·∫°i */}
        {recordedInSession[currentQuestionIndex] && (
          <View className="bg-green-50 border border-green-200 rounded-2xl p-6 mb-4">
            <View className="flex-row items-center justify-between mb-4">
              <View className="flex-row items-center gap-3">
                <View className="w-12 h-12 rounded-full bg-green-500 items-center justify-center">
                  <Ionicons name="checkmark" size={24} color="white" />
                </View>
                <View>
                  <Text className="text-sm text-green-700 font-medium">
                    ƒê·ªô ch√≠nh x√°c ph√°t √¢m
                  </Text>
                  <Text className="text-3xl font-bold text-green-900">
                    {pronunciationScores[currentQuestionIndex]?.toFixed(1) || 0}
                    %
                  </Text>
                </View>
              </View>
            </View>

            {/* Colored text result */}
            {letterCorrectData[currentQuestionIndex] && (
              <View className="mt-4 p-4 bg-white rounded-lg border border-green-200">
                <Text className="text-xs text-gray-600 mb-3 font-medium">
                  Ph√¢n t√≠ch chi ti·∫øt:
                </Text>
                <ColoredText 
                  text={currentQuestion.text} 
                  letterCorrectMask={letterCorrectData[currentQuestionIndex]} 
                />
              </View>
            )}

            {/* IPA Transcripts */}
            <View className="flex-row gap-4 pt-4 border-t border-green-200 mt-4">
              <View className="flex-1 bg-white rounded-lg p-3 border border-green-200">
                <Text className="text-xs text-gray-600 mb-1 font-medium">
                  IPA c·ªßa b·∫°n
                </Text>
                <Text className="text-sm font-mono text-gray-900">
                  {ipaTranscripts[currentQuestionIndex] || "N/A"}
                </Text>
              </View>
              <View className="flex-1 bg-white rounded-lg p-3 border border-green-200">
                <Text className="text-xs text-gray-600 mb-1 font-medium">
                  IPA chu·∫©n
                </Text>
                <Text className="text-sm font-mono text-gray-900">
                  {realIpaTranscripts[currentQuestionIndex] || "N/A"}
                </Text>
              </View>
            </View>

            {/* Play recording button */}
            <TouchableOpacity
              onPress={handlePlayRecording}
              disabled={isPlayingAudio}
              className="bg-purple-50 border border-purple-200 rounded-[50px] py-3 items-center mt-4"
              style={{ opacity: isPlayingAudio ? 0.5 : 1 }}
            >
              <View className="flex-row items-center gap-2">
                {isPlayingAudio ? (
                  <ActivityIndicator size="small" color="#7C3AED" />
                ) : (
                  <Ionicons name="play" size={20} color="#7C3AED" />
                )}
                <Text className="text-purple-700 font-semibold">
                  {isPlayingAudio ? "ƒêang ph√°t..." : "Nghe l·∫°i b·∫£n ghi"}
                </Text>
              </View>
            </TouchableOpacity>
          </View>
        )}
      </ScrollView>

      {/* Footer Navigation with Recording Button */}
      <View className="bg-white border-t border-gray-200 px-4 py-3">
        {/* Recording status text */}
        <Text className="text-center text-sm font-medium text-gray-600 mb-2">
          {isProcessingAudio
            ? "ƒêang x·ª≠ l√Ω..."
            : isRecording
              ? "ƒêang ghi √¢m - Nh·∫•n ƒë·ªÉ d·ª´ng"
              : recorded[currentQuestionIndex]
                ? "Nh·∫•n ƒë·ªÉ ghi l·∫°i"
                : "Nh·∫•n micro ƒë·ªÉ ghi √¢m"}
        </Text>
        
        <View className="flex-row items-center justify-between">
          {/* Previous Button */}
          <TouchableOpacity
            onPress={handlePreviousQuestion}
            disabled={currentQuestionIndex === 0}
            className={`flex-row items-center px-4 py-3 rounded-xl border ${currentQuestionIndex === 0
                ? "border-gray-200 bg-gray-100"
                : "border-blue-500 bg-white"
              }`}
          >
            <Ionicons
              name="arrow-back"
              size={16}
              color={currentQuestionIndex === 0 ? "#9CA3AF" : "#3B82F6"}
            />
            <Text
              className={`ml-1 font-semibold text-sm ${currentQuestionIndex === 0 ? "text-gray-400" : "text-blue-600"
                }`}
            >
              Tr∆∞·ªõc
            </Text>
          </TouchableOpacity>

          {/* Recording Button - Center */}
          <TouchableOpacity
            onPress={handleRecord}
            disabled={isProcessingAudio}
            className={`w-20 h-20 rounded-full items-center justify-center shadow-lg ${isRecording
                ? "bg-red-500"
                : recorded[currentQuestionIndex]
                  ? "bg-green-500"
                  : "bg-blue-500"
              }`}
            style={{ opacity: isProcessingAudio ? 0.5 : 1 }}
          >
            {isProcessingAudio ? (
              <ActivityIndicator size="large" color="white" />
            ) : isRecording ? (
              <View className="w-6 h-6 bg-white rounded" />
            ) : (
              <Ionicons name="mic" size={36} color="white" />
            )}
          </TouchableOpacity>

          {/* Next Button */}
          {currentQuestionIndex === totalQuestions - 1 ? (
            <TouchableOpacity
              onPress={() => navigation.goBack()}
              className="flex-row items-center px-4 py-3 rounded-xl bg-green-600"
            >
              <Ionicons name="home" size={18} color="white" />
              <Text className="ml-1 text-white font-semibold text-sm">
                Xong
              </Text>
            </TouchableOpacity>
          ) : (
            <TouchableOpacity
              onPress={handleNextQuestion}
              className="flex-row items-center px-4 py-3 rounded-xl bg-blue-600"
            >
              <Text className="font-semibold text-sm text-white">
                Ti·∫øp
              </Text>
              <Ionicons
                name="arrow-forward"
                size={16}
                color="white"
                style={{ marginLeft: 4 }}
              />
            </TouchableOpacity>
          )}
        </View>
      </View>
    </SafeAreaView>
  );
};

export default ExerciseScreen;
